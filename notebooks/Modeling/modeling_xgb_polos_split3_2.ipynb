{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e52f566f-d9d0-43ab-b6b1-65a3961a1cd4",
   "metadata": {},
   "source": [
    "# Modeling - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cac22fe-1f45-499a-afe2-dcc2c0d42aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../../src')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "from modeling import train_model, save_model\n",
    "from tuning import random_search_tuning\n",
    "from utils import  generate_combinations, generate_dataset_split, save_combination\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f373d6d-f13a-4e54-82dd-b56858bbaea0",
   "metadata": {},
   "source": [
    "## Parameters for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5acff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'objective': ['binary:logistic'],\n",
    "    'eval_metric': ['aucpr'],\n",
    "    'scale_pos_weight': np.arange(0, 30, 5),\n",
    "    'learning_rate': np.arange(0.001, 0.1, 0.005),\n",
    "    'max_depth': np.arange(2, 8),\n",
    "    'n_estimators': np.arange(50, 150, 10),\n",
    "    'subsample': np.arange(0.3, 0.9, 0.1),\n",
    "    'colsample_bytree': np.arange(0.6, 1.0, 0.05),\n",
    "    'gamma': np.arange(0.1, 5, 0.1),\n",
    "    'early_stopping_rounds': np.arange(5, 15, 5)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd493441",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef26aa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cities_siglas = {\n",
    "    \"A\": \"Porto Alegre\",\n",
    "    \"B\": \"Marabá\",\n",
    "    \"C\": \"Brasília\",\n",
    "    \"D\": \"Belo Horizonte\",\n",
    "    \"E\": \"Juazeiro do Norte\",\n",
    "    \"F\": \"Recife\"\n",
    "}\n",
    "\n",
    "cities = [\"Porto Alegre\", \"Marabá\", \"Brasília\", \"Belo Horizonte\", \"Juazeiro do Norte\", \"Recife\"]\n",
    "\n",
    "polos_sigla = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "polos = [cities_siglas[s] for s in polos_sigla]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4d998c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = []\n",
    "for i in range(0, len(polos_sigla)):\n",
    "    splits.append(generate_combinations(polos[:i] + polos[i+1:], 3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90194cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinação 0: [['Marabá', 'Brasília', 'Belo Horizonte'], ['Juazeiro do Norte', 'Recife']] training\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Acer\\OneDrive\\Documentos\\GitHub\\xai-nui-classification\\notebooks\\Modeling\\modeling_xgb_polos_split3_2.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Acer/OneDrive/Documentos/GitHub/xai-nui-classification/notebooks/Modeling/modeling_xgb_polos_split3_2.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m clf \u001b[39m=\u001b[39m XGBClassifier()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Acer/OneDrive/Documentos/GitHub/xai-nui-classification/notebooks/Modeling/modeling_xgb_polos_split3_2.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model \u001b[39m=\u001b[39m random_search_tuning(clf, parameters)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Acer/OneDrive/Documentos/GitHub/xai-nui-classification/notebooks/Modeling/modeling_xgb_polos_split3_2.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model \u001b[39m=\u001b[39m train_model(model, X_train, y_train, [(X_val, y_val)])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Acer/OneDrive/Documentos/GitHub/xai-nui-classification/notebooks/Modeling/modeling_xgb_polos_split3_2.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39mbest_estimator_)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Acer/OneDrive/Documentos/GitHub/xai-nui-classification/notebooks/Modeling/modeling_xgb_polos_split3_2.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m models\u001b[39m.\u001b[39mappend(model)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\OneDrive\\Documentos\\GitHub\\xai-nui-classification\\notebooks\\Modeling\\../../src\\modeling.py:9\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, X_train, y_train, evaluation)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_model\u001b[39m(model, X_train, y_train, evaluation):\n\u001b[1;32m----> 9\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train, y_train, eval_set\u001b[39m=\u001b[39;49mevaluation, verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     10\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\Acer\\OneDrive\\Documentos\\GitHub\\xai-nui-classification\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Acer\\OneDrive\\Documentos\\GitHub\\xai-nui-classification\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1767\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1768\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1769\u001b[0m         ParameterSampler(\n\u001b[0;32m   1770\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[0;32m   1771\u001b[0m         )\n\u001b[0;32m   1772\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Acer\\OneDrive\\Documentos\\GitHub\\xai-nui-classification\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:834\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[0;32m    821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;00m product(\n\u001b[1;32m--> 834\u001b[0m         \u001b[39menumerate\u001b[39m(candidate_params), \u001b[39menumerate\u001b[39m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Acer\\OneDrive\\Documentos\\GitHub\\xai-nui-classification\\venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:771\u001b[0m, in \u001b[0;36mStratifiedKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msplit\u001b[39m(\u001b[39mself\u001b[39m, X, y, groups\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    738\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \n\u001b[0;32m    740\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[39m    to an integer.\u001b[39;00m\n\u001b[0;32m    770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 771\u001b[0m     y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m\"\u001b[39;49m, ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, dtype\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    772\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39msplit(X, y, groups)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\OneDrive\\Documentos\\GitHub\\xai-nui-classification\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:931\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n\u001b[0;32m    930\u001b[0m     \u001b[39mif\u001b[39;00m n_samples \u001b[39m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 931\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    932\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m sample(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    933\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    934\u001b[0m             \u001b[39m%\u001b[39m (n_samples, array\u001b[39m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    935\u001b[0m         )\n\u001b[0;32m    937\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_features \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    938\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(0, len(splits)):\n",
    "    models = []\n",
    "    save_combination(f'split3_2/{cities[i]}', \"multiclass\", splits[i])\n",
    "    for idx, combination in enumerate(splits[i], start=0):\n",
    "        print(f\"Combinação {idx}: {combination} training\")\n",
    "        X_train, y_train = generate_dataset_split(combination[0], \"multiclass\")\n",
    "        X_val, y_val = generate_dataset_split(combination[1], \"multiclass\")\n",
    "        clf = XGBClassifier()\n",
    "        model = random_search_tuning(clf, parameters)\n",
    "        model = train_model(model, X_train, y_train, [(X_val, y_val)])\n",
    "        print(model.best_estimator_)\n",
    "        models.append(model)\n",
    "    for j in range(0, len(models)):\n",
    "        pickle.dump(models[j], open(f\"../../data/models/multiclass/split3_2/{cities[i]}/xgb_{j}.sav\", 'wb'))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Empty DataFrame\n",
       " Columns: [Declividade, Curvatura, APP30m, UCIntegral, AltaTensao, Vias50m, Dutovias, IndiceForma, DomSIden, DomSIlu, DomSPav, DomSCal, DomSFio, DomSBue, DomSArb, DomSEne, DomSAgua, DomSMed, DomSEsg, DomSRedeEsg, DomCLixAc, DomSColLix, DomSColLixDir, DomApto, DomCasa, DomVila, DomImpr, DomAdeq, DomAdeqSN, DomAdeqCN, DomSemiAdeq, DomInadeq, DomPosseOutro, DomSBan, DomNBanDom, DomNBanHab, AguaRede, AguaNascente, AguaCisterna, AguaOutra, EsgotoRede, EsgotoSeptica, EsgotoRudimentar, EsgotoVala, EsgotoRio, EsgotoOutro, LixoLimpeza, LixoQueimado, LixoAterrado, LixoJogado, LixoRio, LixoOutro, LixoCacamba, Ren0SM, RenMeioSM, Ren1a2SM, Ren3SM, RenPopDependente, RenPopAtiva, RenResp3SM, RenRespMedia, NDenDom, NDenPop, NMoradores, NPes10Alf, NRespAlf, NRespFem, NRespIdade, NResp30, NResp30NAlf]\n",
       " Index: []\n",
       " \n",
       " [0 rows x 70 columns],\n",
       " Series([], Name: y, dtype: float64),\n",
       " 'c:\\\\Users\\\\Acer\\\\OneDrive\\\\Documentos\\\\GitHub\\\\xai-nui-classification\\\\data\\\\model_input\\\\multiclass\\\\X_Recife.pkl')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_dataset_split([\"Recife\"], \"multiclass\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
