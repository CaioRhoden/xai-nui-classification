{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e52f566f-d9d0-43ab-b6b1-65a3961a1cd4",
   "metadata": {},
   "source": [
    "# Modeling - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cac22fe-1f45-499a-afe2-dcc2c0d42aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../../src')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "from modeling import train_model, save_model\n",
    "from tuning import find_best_model\n",
    "from utils import  generate_combinations, generate_dataset_split, save_combination\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f373d6d-f13a-4e54-82dd-b56858bbaea0",
   "metadata": {},
   "source": [
    "## Parameters for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5acff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'learning_rate': np.arange(0.001, 0.1, 0.005),\n",
    "    'max_depth': np.arange(2, 8),\n",
    "    'n_estimators': np.arange(50, 150, 10),\n",
    "    'subsample': np.arange(0.3, 0.9, 0.1),\n",
    "    'colsample_bytree': np.arange(0.6, 1.0, 0.05),\n",
    "    'gamma': np.arange(0.1, 5, 0.1),\n",
    "    'early_stopping_rounds': np.arange(5, 15, 5),\n",
    "    'objective': ['multi:softprob'], \n",
    "    'num_class': [3],\n",
    "    'eval_metric':['auc']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd493441",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef26aa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cities_siglas = {\n",
    "    \"A\": \"Porto Alegre\",\n",
    "    \"B\": \"Marabá\",\n",
    "    \"C\": \"Brasília\",\n",
    "    \"D\": \"Belo Horizonte\",\n",
    "    \"E\": \"Juazeiro do Norte\",\n",
    "    \"F\": \"Recife\"\n",
    "}\n",
    "\n",
    "cities = [\"Porto Alegre\", \"Marabá\", \"Brasília\", \"Belo Horizonte\", \"Juazeiro do Norte\", \"Recife\"]\n",
    "\n",
    "polos_sigla = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "polos = [cities_siglas[s] for s in polos_sigla]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e405a061-f5ab-4354-a076-eaf7789f8af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = []\n",
    "for i in range(0, len(polos_sigla)):\n",
    "    splits.append(generate_combinations(polos[:i] + polos[i+1:], 3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b33579-b5d7-42ad-b720-fc20ff64bb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinação 0: [['Marabá', 'Brasília', 'Belo Horizonte'], ['Juazeiro do Norte', 'Recife']] training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-20 04:48:07,721] A new study created in memory with name: no-name-bf45a938-64f4-4b14-945c-68accf9a7bda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7483b14e0ebf47db8139eb25fd1048a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-03-20 04:50:07,865] Trial 0 finished with value: 0.7362601999840908 and parameters: {'n_estimators': 115, 'learning_rate': 0.019573198528162947, 'max_depth': 7, 'subsample': 0.37451055976457087, 'colsample_bytree': 0.8263774722049284, 'min_child_weight': 5, 'gamma': 3.270081185327834}. Best is trial 0 with value: 0.7362601999840908.\n",
      "[I 2024-03-20 04:52:29,584] Trial 1 finished with value: 0.694430764599113 and parameters: {'n_estimators': 143, 'learning_rate': 0.001807203712647238, 'max_depth': 7, 'subsample': 0.586874125581083, 'colsample_bytree': 0.7485561230968918, 'min_child_weight': 13, 'gamma': 1.102801187907732}. Best is trial 0 with value: 0.7362601999840908.\n",
      "[I 2024-03-20 04:53:31,934] Trial 2 finished with value: 0.7324987525888625 and parameters: {'n_estimators': 101, 'learning_rate': 0.015507559466614338, 'max_depth': 2, 'subsample': 0.8593242853559373, 'colsample_bytree': 0.9928970422175601, 'min_child_weight': 20, 'gamma': 4.52334844647297}. Best is trial 0 with value: 0.7362601999840908.\n",
      "[I 2024-03-20 04:55:40,828] Trial 3 finished with value: 0.7422826088236748 and parameters: {'n_estimators': 118, 'learning_rate': 0.04582249626672975, 'max_depth': 7, 'subsample': 0.6413950257800723, 'colsample_bytree': 0.9561947187000607, 'min_child_weight': 10, 'gamma': 3.3363226678841054}. Best is trial 3 with value: 0.7422826088236748.\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(splits)):\n",
    "    models = []\n",
    "    save_combination(f'split3_2/{cities[i]}', \"binary\", splits[i])\n",
    "    for idx, combination in enumerate(splits[i], start=0):\n",
    "        print(f\"Combinação {idx}: {combination} training\")\n",
    "        X_train, y_train = generate_dataset_split(combination[0], \"binary\")\n",
    "        X_val, y_val = generate_dataset_split(combination[1], \"binary\")\n",
    "        best_params = find_best_model(\"xgb\", X_train, y_train, X_val, y_val, trials=25)\n",
    "        model = XGBClassifier(**best_params.params, random_state=42).fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "        models.append(model)\n",
    "        break\n",
    "    for j in range(0, len(models)):\n",
    "        pickle.dump(models[j], open(f\"../../data/models/binary/split3_2/{cities[i]}/xgb_{j}.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca9e287-9743-4603-b315-8e5ec162b2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = []\n",
    "for i in range(0, len(polos_sigla)):\n",
    "    splits.append(generate_combinations(polos[:i] + polos[i+1:], 4, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e358f3a9-7222-4645-ad24-f1c8eede7e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0, len(splits)):\n",
    "    models = []\n",
    "    save_combination(f'split4_1/{cities[i]}', \"binary\", splits[i])\n",
    "    for idx, combination in enumerate(splits[i], start=0):\n",
    "        print(f\"Combinação {idx}: {combination} training\")\n",
    "        X_train, y_train = generate_dataset_split(combination[0], \"binary\")\n",
    "        X_val, y_val = generate_dataset_split(combination[1], \"binary\")\n",
    "        best_params = find_best_model(\"xgb\", X_train, y_train, X_val, y_val, trials=25)\n",
    "        model = XGBClassifier(**best_params.params, random_state=42).fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "        models.append(model)\n",
    "        break\n",
    "    for j in range(0, len(models)):\n",
    "        pickle.dump(models[j], open(f\"../../data/models/binary/split4_1/{cities[i]}/xgb_{j}.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d998c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = []\n",
    "for i in range(0, len(polos_sigla)):\n",
    "    splits.append(generate_combinations(polos[:i] + polos[i+1:], 3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90194cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0, len(splits)):\n",
    "    models = []\n",
    "    save_combination(f'split3_2/{cities[i]}', \"binary\", splits[i])\n",
    "    for idx, combination in enumerate(splits[i], start=0):\n",
    "        print(f\"Combinação {idx}: {combination} training\")\n",
    "        X_train, y_train = generate_dataset_split(combination[0], \"binary\")\n",
    "        X_val, y_val = generate_dataset_split(combination[1], \"binary\")\n",
    "        best_params = find_best_model(\"xgb\", X_train, y_train, X_val, y_val, trials=25)\n",
    "        model = XGBClassifier(**best_params.params, random_state=42).fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "        models.append(model)\n",
    "        break\n",
    "    for j in range(0, len(models)):\n",
    "        pickle.dump(models[j], open(f\"../../data/models/binary/split3_2/{cities[i]}/xgb_{j}.sav\", 'wb'))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e2e77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = []\n",
    "for i in range(0, len(polos_sigla)):\n",
    "    splits.append(generate_combinations(polos[:i] + polos[i+1:], 4, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0105cd37-1372-4c7e-acdf-3c526d2113f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0, len(splits)):\n",
    "    models = []\n",
    "    save_combination(f'split4_1/{cities[i]}', \"binary\", splits[i])\n",
    "    for idx, combination in enumerate(splits[i], start=0):\n",
    "        print(f\"Combinação {idx}: {combination} training\")\n",
    "        X_train, y_train = generate_dataset_split(combination[0], \"binary\")\n",
    "        X_val, y_val = generate_dataset_split(combination[1], \"binary\")\n",
    "        best_params = find_best_model(\"xgb\", X_train, y_train, X_val, y_val, trials=25)\n",
    "        model = XGBClassifier(**best_params.params, random_state=42).fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "        models.append(model)\n",
    "        break\n",
    "    for j in range(0, len(models)):\n",
    "        pickle.dump(models[j], open(f\"../../data/models/binary/split4_1/{cities[i]}/xgb_{j}.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbc220a-2ebd-4d9e-8fd0-ddf197c36a66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
