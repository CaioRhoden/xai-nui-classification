{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Binary Classification\n",
    "\n",
    "In this notebook will be evaluated the performance of five different basemodels\n",
    "\n",
    "- XGBoost\n",
    "- CatBoost\n",
    "- RandomForest\n",
    "- LogisticRegression\n",
    "- MLP\n",
    "\n",
    "It will be training five different models with a different data split each\\\n",
    "The data split will consist on 2 cities for training, 2 cities for validation and 2 cities for evaluation \\\n",
    "The evaluation will use the mean ROCAU metrics of the five models for each basemodel\\\n",
    "The models will have learning rate fixed to 0.01 and 10 early-stopping rounds (when applied) \n",
    "\n",
    "**Results**\n",
    "\n",
    "| Model           |   ROCAU       |\n",
    "| -----------     | -----------   |\n",
    "| XGBoost         |    0.772      |\n",
    "| Catboost        |               |\n",
    "| RandomForest    |               |\n",
    "| LR              |    0.688      |\n",
    "| MLP             |               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Random Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from random_data_generator import random_data_generator\n",
    "\n",
    "#grid searh\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#models\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = random_data_generator(\"binary\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMEÇOU\n",
      "FOI\n",
      "COMEÇOU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <bound method DataIter._next_wrapper of <xgboost.data.SingleBatchInternalIter object at 0x0000026A99A7FC50>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\caior\\OneDrive\\Documentos\\GitHub\\xai-nui-classification\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 588, in _next_wrapper\n",
      "    def _next_wrapper(self, this: None) -> int:  # pylint: disable=unused-argument\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "xgboost_params = {\n",
    "    'learning_rate': np.arange(0.001, 0.1, 0.005),\n",
    "    'max_depth': np.arange(2, 8),\n",
    "    'n_estimators': np.arange(50, 150, 10),\n",
    "    'subsample': np.arange(0.3, 0.9, 0.1),\n",
    "    'colsample_bytree': np.arange(0.6, 1.0, 0.05),\n",
    "    'gamma': np.arange(0.1, 5, 0.1),\n",
    "    'early_stopping_rounds': np.arange(5, 15, 5),\n",
    "    'eval_metric':['auc']\n",
    "}\n",
    "\n",
    "scores = []\n",
    "for i in range(0, len(dataset)):\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test = dataset[i][0], dataset[i][1], dataset[i][2], dataset[i][3], dataset[i][4], dataset[i][5]\n",
    "    random_search = RandomizedSearchCV(XGBClassifier(random_state=42), param_distributions=xgboost_params, cv=5, scoring='roc_auc').fit(x_train, y_train, eval_set=[(x_val, y_val)], verbose=False)\n",
    "    best_params = random_search.best_params_\n",
    "    xgb_clf = XGBClassifier(**best_params, random_state=42).fit(x_train, y_train, eval_set=[(x_val, y_val)], verbose=False)\n",
    "    y_pred = xgb_clf.predict_proba(x_test)\n",
    "    scores.append(roc_auc_score(y_test, y_pred[:,1]))\n",
    "mean =  np.mean(np.array(scores))\n",
    "print(scores)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMEÇOU\n"
     ]
    }
   ],
   "source": [
    "catboost_params = {\n",
    "    'learning_rate': np.arange(0.001, 0.1, 0.005),\n",
    "    'depth': np.arange(4, 10),\n",
    "    'iterations': np.arange(50, 150, 10),\n",
    "    'l2_leaf_reg': np.arange(0.1, 1, 0.2),\n",
    "    'eval_metric':['AUC'],\n",
    "    'early_stopping_rounds': np.arange(5, 15, 5),\n",
    "\n",
    "}\n",
    "\n",
    "scores = []\n",
    "for i in range(0, len(dataset)):\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test = dataset[i][0], dataset[i][1], dataset[i][2], dataset[i][3], dataset[i][4], dataset[i][5]\n",
    "    print(\"COMEÇOU\")\n",
    "    random_search = RandomizedSearchCV(CatBoostClassifier(random_seed=42), param_distributions=catboost_params, cv=5, scoring='roc_auc').fit(x_train, y_train, eval_set=[(x_val, y_val)], verbose=False)\n",
    "    best_params = random_search.best_params_\n",
    "    cat_clf = CatBoostClassifier(**best_params, random_seed=42).fit(x_train, y_train, eval_set=[(x_val, y_val)], verbose=False)\n",
    "    y_pred = cat_clf.predict_proba(x_test)\n",
    "    scores.append(roc_auc_score(y_test, y_pred[:,1]))\n",
    "    print(\"FOI\")\n",
    "mean =  np.mean(np.array(scores))\n",
    "print(scores)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7479586532342586, 0.70459258589082, 0.7910507940324134, 0.7568966029590902, 0.7461569741946842]\n",
      "0.7493311220622532\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in range(0, len(dataset)):\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test = dataset[i][0], dataset[i][1], dataset[i][2], dataset[i][3], dataset[i][4], dataset[i][5]\n",
    "    rf_clf = RandomForestClassifier(random_state=42, verbose=False)\n",
    "    rf_clf.fit(x_train, y_train)\n",
    "    y_pred = rf_clf.predict_proba(x_test)\n",
    "    scores.append(roc_auc_score(y_test, y_pred[:,1]))\n",
    "mean =  np.mean(np.array(scores))\n",
    "print(scores)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caior\\OneDrive\\Documentos\\GitHub\\xai-nui-classification\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\caior\\OneDrive\\Documentos\\GitHub\\xai-nui-classification\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\caior\\OneDrive\\Documentos\\GitHub\\xai-nui-classification\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\caior\\OneDrive\\Documentos\\GitHub\\xai-nui-classification\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\caior\\OneDrive\\Documentos\\GitHub\\xai-nui-classification\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63691483025621, 0.6219127525835161, 0.4746259835525888, 0.5993430897283265, 0.7113281637915438]\n",
      "0.608824963982437\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in range(0, len(dataset)):\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test = dataset[i][0], dataset[i][1], dataset[i][2], dataset[i][3], dataset[i][4], dataset[i][5]\n",
    "    lr_clf = LogisticRegression(random_state=42, verbose=False, solver=\"sag\")\n",
    "    lr_clf.fit(x_train, y_train)\n",
    "    y_pred = lr_clf.predict_proba(x_test)\n",
    "    scores.append(roc_auc_score(y_test, y_pred[:,1]))\n",
    "mean =  np.mean(np.array(scores))\n",
    "print(scores)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. MLP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
